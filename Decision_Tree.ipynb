{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# A Multi-agent Case-based Reasoning Intrusion Detection System\n",
        "# -------------------------------------------------------------------\n",
        "# Re-implementation using a CPU-Based Decision Tree with scikit-learn\n",
        "#\n",
        "# This version evaluates the final model on a 50,000-case random sample\n",
        "# from the test set for consistency with other methods.\n",
        "#\n",
        "# Setup:\n",
        "# pip install pandas numpy scikit-learn\n",
        "#\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "# Suppress potential warnings from scikit-learn for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "def run_decision_tree_classifier():\n",
        "    \"\"\"\n",
        "    Loads, preprocesses, trains, and evaluates a Decision Tree model on the CPU.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- 1. Load Data ---\n",
        "        print(\"Loading UNSW-NB15 training and testing data... üìÇ\")\n",
        "        train_df = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "        test_df = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "        # Combine for consistent preprocessing, then split later\n",
        "        full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "        full_df.columns = full_df.columns.str.strip()\n",
        "\n",
        "        # Drop unnecessary columns\n",
        "        full_df = full_df.drop(['id', 'label'], axis=1, errors='ignore')\n",
        "\n",
        "        # --- 2. Data Preparation ---\n",
        "        print(\"Preparing data for the model... üìä\")\n",
        "        X = full_df.drop('attack_cat', axis=1)\n",
        "        y = full_df['attack_cat']\n",
        "\n",
        "        numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "        categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "        # Split the data back into training and full testing sets\n",
        "        X_train, X_test = X.iloc[:len(train_df)], X.iloc[len(train_df):]\n",
        "        y_train, y_test = y.iloc[:len(train_df)], y.iloc[len(train_df):]\n",
        "\n",
        "        # --- 3. Preprocessing Pipeline ---\n",
        "        print(\"Building preprocessing pipeline... ‚öôÔ∏è\")\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), numeric_features),\n",
        "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "            ])\n",
        "\n",
        "        # --- 4. Model Training ---\n",
        "        print(\"Training DecisionTreeClassifier... üå≥\")\n",
        "        dt_pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', DecisionTreeClassifier(\n",
        "                max_depth=15,\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        # Train the model on the full training set\n",
        "        dt_pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # --- 5. Evaluation on a Sample of the Test Set ---\n",
        "        EVALUATION_SAMPLE_SIZE = 50000\n",
        "        print(f\"Evaluating the model on a random sample of {EVALUATION_SAMPLE_SIZE} test cases... üìà\")\n",
        "\n",
        "        # Create the random sample from the test set\n",
        "        X_test_sample = X_test.sample(n=EVALUATION_SAMPLE_SIZE, random_state=42)\n",
        "        y_test_sample = y_test.loc[X_test_sample.index]\n",
        "\n",
        "        # Run predictions on the sample\n",
        "        y_pred = dt_pipeline.predict(X_test_sample)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"            CPU-Based Decision Tree Results\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Generate and print the classification report from the sample\n",
        "        print(\"\\n--- Classification Report ---\")\n",
        "        report = classification_report(y_test_sample, y_pred, zero_division=0)\n",
        "        print(report)\n",
        "\n",
        "        # Generate and print the confusion matrix from the sample\n",
        "        print(\"\\n--- Confusion Matrix ---\")\n",
        "        all_labels = y.unique()\n",
        "        cm = confusion_matrix(y_test_sample, y_pred, labels=all_labels)\n",
        "        cm_df = pd.DataFrame(cm, index=all_labels, columns=all_labels)\n",
        "        print(cm_df)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nERROR: Make sure 'UNSW_NB15_training-set.csv' and 'UNSW_NB15_testing-set.csv' are present.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "# =================================\n",
        "# Main Execution Block\n",
        "# =================================\n",
        "if __name__ == \"__main__\":\n",
        "    run_decision_tree_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXOIodCyecEO",
        "outputId": "3431eafc-360a-49a7-e3c0-e721ec0213bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading UNSW-NB15 training and testing data... üìÇ\n",
            "Preparing data for the model... üìä\n",
            "Building preprocessing pipeline... ‚öôÔ∏è\n",
            "Training DecisionTreeClassifier... üå≥\n",
            "Evaluating the model on a random sample of 50000 test cases... üìà\n",
            "\n",
            "==================================================\n",
            "            CPU-Based Decision Tree Results\n",
            "==================================================\n",
            "\n",
            "--- Classification Report ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.02      0.06      0.03       398\n",
            "      Backdoor       0.04      0.09      0.06       378\n",
            "           DoS       0.41      0.11      0.18      2452\n",
            "      Exploits       0.59      0.82      0.69      6801\n",
            "       Fuzzers       0.30      0.46      0.36      3685\n",
            "       Generic       0.99      0.98      0.98     11369\n",
            "        Normal       0.94      0.79      0.86     22552\n",
            "Reconnaissance       0.93      0.78      0.85      2089\n",
            "     Shellcode       0.40      0.73      0.51       243\n",
            "         Worms       0.66      0.64      0.65        33\n",
            "\n",
            "      accuracy                           0.77     50000\n",
            "     macro avg       0.53      0.54      0.52     50000\n",
            "  weighted avg       0.82      0.77      0.78     50000\n",
            "\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "                Normal  Backdoor  Analysis  Fuzzers  Shellcode  \\\n",
            "Normal           17804         0       314     3763         49   \n",
            "Backdoor             3        35        31        9          6   \n",
            "Analysis             2        47        23        0          0   \n",
            "Fuzzers            873        69        83     1698         97   \n",
            "Shellcode           10         1         0       19        177   \n",
            "Reconnaissance      27        37        39       21         25   \n",
            "Exploits            86       291       394      112         50   \n",
            "DoS                 32       309       358       52         30   \n",
            "Worms                0         0         0        1          0   \n",
            "Generic              5         3         0       29         12   \n",
            "\n",
            "                Reconnaissance  Exploits  DoS  Worms  Generic  \n",
            "Normal                       7       549   61      0        5  \n",
            "Backdoor                     0       265   24      0        5  \n",
            "Analysis                     0       302   23      0        1  \n",
            "Fuzzers                      7       787   64      2        5  \n",
            "Shellcode                    1        31    3      0        1  \n",
            "Reconnaissance            1632       294    8      2        4  \n",
            "Exploits                    88      5548  180      6       46  \n",
            "DoS                         11      1365  273      0       22  \n",
            "Worms                        0        10    1     21        0  \n",
            "Generic                      2       194   26      1    11097  \n"
          ]
        }
      ]
    }
  ]
}