{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "def run_deep_learning_classifier():\n",
        "    \"\"\"\n",
        "    Loads, preprocesses, builds, trains, and evaluates a neural network model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- 1. Load Data ---\n",
        "        print(\"Loading UNSW-NB15 training and testing data... 📂\")\n",
        "        train_df = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "        test_df = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "\n",
        "        full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "        full_df.columns = full_df.columns.str.strip()\n",
        "        full_df = full_df.drop(['id', 'label'], axis=1, errors='ignore')\n",
        "\n",
        "        # --- 2. Data Preparation ---\n",
        "        print(\"Preparing data for the model... 📊\")\n",
        "        X = full_df.drop('attack_cat', axis=1)\n",
        "        y = full_df['attack_cat']\n",
        "\n",
        "        numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "        categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "        # --- 3. Preprocessing ---\n",
        "        print(\"Preprocessing features and labels... ⚙️\")\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), numeric_features),\n",
        "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "            ], remainder='passthrough')\n",
        "\n",
        "        X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "        y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "        # Split data back into full training and testing sets\n",
        "        train_len = len(train_df)\n",
        "        X_train, X_test = X_processed[:train_len], X_processed[train_len:]\n",
        "        y_train, y_test = y_categorical[:train_len], y_categorical[train_len:]\n",
        "\n",
        "        num_classes = len(label_encoder.classes_)\n",
        "\n",
        "        # --- 4. Build the Neural Network Model ---\n",
        "        print(\"Building the neural network model... 🧠\")\n",
        "        model = Sequential([\n",
        "            Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "            Dropout(0.3),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.3),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        # --- 5. Train the Model ---\n",
        "        print(\"\\nTraining the model... (This will utilize the GPU if available) 🚀\")\n",
        "        # Validation during training still uses the full test set for a stable metric\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=20,\n",
        "            batch_size=64,\n",
        "            validation_data=(X_test, y_test),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # --- 6. Create Test Set Sample ---\n",
        "        EVALUATION_SAMPLE_SIZE = 50000\n",
        "        print(f\"\\nCreating a random sample of {EVALUATION_SAMPLE_SIZE} cases from the test set for final evaluation...\")\n",
        "\n",
        "        # Generate random indices to select a sample\n",
        "        num_test_samples = X_test.shape[0]\n",
        "        sample_indices = np.random.choice(num_test_samples, EVALUATION_SAMPLE_SIZE, replace=False)\n",
        "\n",
        "        # Create the sample sets\n",
        "        X_test_sample = X_test[sample_indices]\n",
        "        y_test_sample = y_test[sample_indices]\n",
        "\n",
        "        # --- 7. Evaluation on the Sample ---\n",
        "        print(f\"Evaluating the final model on the {EVALUATION_SAMPLE_SIZE}-case sample... 📈\")\n",
        "        loss, accuracy = model.evaluate(X_test_sample, y_test_sample, verbose=0)\n",
        "        print(f\"Sample Test Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Sample Test Loss: {loss:.4f}\")\n",
        "\n",
        "        # Get predictions for the sample to generate a detailed report\n",
        "        y_pred_probs = model.predict(X_test_sample)\n",
        "        y_pred_encoded = np.argmax(y_pred_probs, axis=1)\n",
        "        y_test_encoded = np.argmax(y_test_sample, axis=1)\n",
        "\n",
        "        # Decode the labels back to their original string format for the report\n",
        "        y_pred_labels = label_encoder.inverse_transform(y_pred_encoded)\n",
        "        y_test_labels = label_encoder.inverse_transform(y_test_encoded)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"            Deep Learning (MLP) Results\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        print(\"\\n--- Classification Report ---\")\n",
        "        report = classification_report(y_test_labels, y_pred_labels, zero_division=0)\n",
        "        print(report)\n",
        "\n",
        "        print(\"\\n--- Confusion Matrix ---\")\n",
        "        cm = confusion_matrix(y_test_labels, y_pred_labels, labels=label_encoder.classes_)\n",
        "        cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
        "        print(cm_df)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nERROR: Make sure 'UNSW_NB15_training-set.csv' and 'UNSW_NB15_testing-set.csv' are present.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        print(\"Please ensure TensorFlow is installed correctly.\")\n",
        "\n",
        "# =================================\n",
        "# Main Execution Block\n",
        "# =================================\n",
        "if __name__ == \"__main__\":\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        print(f\"GPU(s) detected: {len(gpus)}. TensorFlow will use the GPU for training.\")\n",
        "    else:\n",
        "        print(\"No GPU detected. TensorFlow will use the CPU.\")\n",
        "\n",
        "    run_deep_learning_classifier()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUVbOgraXWzV",
        "outputId": "c192ae1b-8cdd-4944-8c40-febcb53cc0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU(s) detected: 1. TensorFlow will use the GPU for training.\n",
            "Loading UNSW-NB15 training and testing data... 📂\n",
            "Preparing data for the model... 📊\n",
            "Preprocessing features and labels... ⚙️\n",
            "Building the neural network model... 🧠\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m25,216\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,216</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,122\u001b[0m (133.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,122</span> (133.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,122\u001b[0m (133.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,122</span> (133.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model... (This will utilize the GPU if available) 🚀\n",
            "Epoch 1/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.7946 - val_accuracy: 0.6950 - val_loss: 0.6454\n",
            "Epoch 2/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7783 - loss: 0.5721 - val_accuracy: 0.7138 - val_loss: 0.5812\n",
            "Epoch 3/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.5445 - val_accuracy: 0.7334 - val_loss: 0.5674\n",
            "Epoch 4/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.5307 - val_accuracy: 0.7389 - val_loss: 0.5798\n",
            "Epoch 5/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7924 - loss: 0.5224 - val_accuracy: 0.7235 - val_loss: 0.5693\n",
            "Epoch 6/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.5181 - val_accuracy: 0.7557 - val_loss: 0.5701\n",
            "Epoch 7/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.5122 - val_accuracy: 0.7465 - val_loss: 0.5497\n",
            "Epoch 8/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.5055 - val_accuracy: 0.7695 - val_loss: 0.5377\n",
            "Epoch 9/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.5042 - val_accuracy: 0.7334 - val_loss: 0.5748\n",
            "Epoch 10/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.5015 - val_accuracy: 0.7437 - val_loss: 0.5503\n",
            "Epoch 11/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.7998 - loss: 0.4989 - val_accuracy: 0.7478 - val_loss: 0.5617\n",
            "Epoch 12/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8004 - loss: 0.5000 - val_accuracy: 0.7185 - val_loss: 0.5776\n",
            "Epoch 13/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.4990 - val_accuracy: 0.7696 - val_loss: 0.5389\n",
            "Epoch 14/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 0.4948 - val_accuracy: 0.7824 - val_loss: 0.5320\n",
            "Epoch 15/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.4976 - val_accuracy: 0.7771 - val_loss: 0.5385\n",
            "Epoch 16/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4925 - val_accuracy: 0.7584 - val_loss: 0.5617\n",
            "Epoch 17/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4914 - val_accuracy: 0.7357 - val_loss: 0.5653\n",
            "Epoch 18/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4913 - val_accuracy: 0.7643 - val_loss: 0.5639\n",
            "Epoch 19/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4922 - val_accuracy: 0.7468 - val_loss: 0.5602\n",
            "Epoch 20/20\n",
            "\u001b[1m2740/2740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4913 - val_accuracy: 0.7592 - val_loss: 0.5580\n",
            "\n",
            "Creating a random sample of 50000 cases from the test set for final evaluation...\n",
            "Evaluating the final model on the 50000-case sample... 📈\n",
            "Sample Test Accuracy: 0.7600\n",
            "Sample Test Loss: 0.5559\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
            "\n",
            "==================================================\n",
            "            Deep Learning (MLP) Results\n",
            "==================================================\n",
            "\n",
            "--- Classification Report ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       383\n",
            "      Backdoor       0.09      0.00      0.01       340\n",
            "           DoS       0.60      0.03      0.06      2442\n",
            "      Exploits       0.54      0.94      0.68      6740\n",
            "       Fuzzers       0.30      0.56      0.39      3638\n",
            "       Generic       1.00      0.96      0.98     11539\n",
            "        Normal       0.97      0.74      0.84     22507\n",
            "Reconnaissance       0.73      0.80      0.76      2130\n",
            "     Shellcode       0.33      0.44      0.38       250\n",
            "         Worms       0.80      0.13      0.22        31\n",
            "\n",
            "      accuracy                           0.76     50000\n",
            "     macro avg       0.54      0.46      0.43     50000\n",
            "  weighted avg       0.82      0.76      0.76     50000\n",
            "\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "                Analysis  Backdoor  DoS  Exploits  Fuzzers  Generic  Normal  \\\n",
            "Analysis               0         0    0       379        2        0       1   \n",
            "Backdoor               0         1    0       327        3        0       1   \n",
            "DoS                    0         4   72      2234       39        8      14   \n",
            "Exploits              14         5   20      6322      184        4      38   \n",
            "Fuzzers                0         0    1      1015     2032        0     429   \n",
            "Generic                0         1   23       352       30    11112       1   \n",
            "Normal               295         0    3       714     4461        0   16645   \n",
            "Reconnaissance         0         0    1       391       25        2       5   \n",
            "Shellcode              0         0    0        54       35        0       4   \n",
            "Worms                  0         0    0        24        1        0       0   \n",
            "\n",
            "                Reconnaissance  Shellcode  Worms  \n",
            "Analysis                     1          0      0  \n",
            "Backdoor                     4          4      0  \n",
            "DoS                         31         40      0  \n",
            "Exploits                   115         38      0  \n",
            "Fuzzers                    128         33      0  \n",
            "Generic                      5         14      1  \n",
            "Normal                     301         88      0  \n",
            "Reconnaissance            1704          2      0  \n",
            "Shellcode                   47        110      0  \n",
            "Worms                        0          2      4  \n"
          ]
        }
      ]
    }
  ]
}