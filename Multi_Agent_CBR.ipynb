{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from numba import cuda"
      ],
      "metadata": {
        "id": "09AfiYH4ouht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 types of features: numeric and categorical. Each of them will have different formula for calculating the similarity."
      ],
      "metadata": {
        "id": "8TMfDL7zpAn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numerical features are using:\n",
        "$$\n",
        "\\mathrm{sim_{feature}} = 1 - \\mathrm{diff_{feature}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathrm{diff} = \\frac{|q - c|}{\\max_{\\mathrm{feature}} - \\min_{\\mathrm{feature}}}\n",
        "$$"
      ],
      "metadata": {
        "id": "WKgoDcO6pLNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The categorical features are using if statement.\n",
        "$$\n",
        "\\mathrm{sim}_{\\mathrm{feature}} =\n",
        "\\begin{cases}\n",
        "1, & \\text{if } q = c \\\\\n",
        "0, & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$"
      ],
      "metadata": {
        "id": "fgM4lPIVrdoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then the similarities would be summed with this formula:\n",
        "$$\n",
        "\\mathrm{Total\\_Sim} = \\mathrm{weight}_{\\mathrm{feature}} \\cdot \\mathrm{sim}_{\\mathrm{feature}}\n",
        "$$"
      ],
      "metadata": {
        "id": "rR-Va3uUr7f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def similarity_kernel(d_casebase_numeric, d_casebase_categorical,\n",
        "                      d_query_numeric, d_query_categorical,\n",
        "                      d_weights_numeric, d_weights_categorical,\n",
        "                      d_min_vals, d_max_vals,\n",
        "                      d_similarities_out):\n",
        "    \"\"\"\n",
        "    This CUDA kernel calculates the similarity for one case against the query.\n",
        "    It will be executed by thousands of GPU threads in parallel.\n",
        "    \"\"\"\n",
        "    idx = cuda.grid(1)\n",
        "    if idx >= d_casebase_numeric.shape[0]:\n",
        "        return\n",
        "\n",
        "    total_similarity = 0.0\n",
        "    num_numeric_features = d_casebase_numeric.shape[1]\n",
        "    num_categorical_features = d_casebase_categorical.shape[1]\n",
        "\n",
        "    # Similarity for NUMERIC features\n",
        "    for i in range(num_numeric_features):\n",
        "        weight, query_val, case_val = d_weights_numeric[i], d_query_numeric[i], d_casebase_numeric[idx, i]\n",
        "        max_val, min_val = d_max_vals[i], d_min_vals[i]\n",
        "        sim = 1.0\n",
        "        if max_val != min_val:\n",
        "            normalized_diff = abs(query_val - case_val) / (max_val - min_val)\n",
        "            sim = 1.0 - (normalized_diff * normalized_diff)\n",
        "        total_similarity += weight * sim\n",
        "\n",
        "    # Similarity for CATEGORICAL features\n",
        "    for i in range(num_categorical_features):\n",
        "        weight, query_val, case_val = d_weights_categorical[i], d_query_categorical[i], d_casebase_categorical[idx, i]\n",
        "        sim = 1.0 if query_val == case_val else 0.0\n",
        "        total_similarity += weight * sim\n",
        "\n",
        "    d_similarities_out[idx] = total_similarity"
      ],
      "metadata": {
        "id": "AaQEcf9Bo0Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weighting formula is the one that probably didn't implemented accurately due to minimal information from the paper."
      ],
      "metadata": {
        "id": "c7pQ5ciZxWkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For numeric weighting, I try to use this formula:\n",
        "$$\n",
        "\\mathbf{w}_{\\mathrm{numerical}} = |\\mathrm{mean_{agent}} - \\mathrm{mean_{full}}|\n",
        "$$"
      ],
      "metadata": {
        "id": "DwTKovPjxnXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While categorical weighting use this:\n",
        "$$\n",
        "\\mathbf{w}_{\\mathrm{categorical}} = \\begin{bmatrix} 0.1 & 0.1 & \\dots & 0.1 \\end{bmatrix}_{1 \\times n}\n",
        "$$"
      ],
      "metadata": {
        "id": "mAMMoi-OyyJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When one case is received, each agent will retrieve the most similar from 10 cases from each corresponding agent. Which mean the total would be 100 cases being retrieved (total agent is 10)."
      ],
      "metadata": {
        "id": "1g4-dNPr0z-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From that 100 cases, it will be picked 10 most similar agent. For example from 100 cases, it found that the most 10 similar cases are from:\\\n",
        "Shellcode = 0.999 \\\n",
        "Shellcode = 0.997 \\\n",
        "Generic = 0.988 \\\n",
        "Generic = 0.987 \\\n",
        "Generic = 0.977 \\\n",
        "Generic = 0.945 \\\n",
        "Generic = 0.943 \\\n",
        "Generic = 0.931 \\\n",
        "Generic = 0.919 \\\n",
        "Fuzzer = 0.681 \\\n",
        "Despite Shellcode has the highest similarity, but majority are from Generic category. Therefore, the new case is categorized as Generic."
      ],
      "metadata": {
        "id": "Y72ymrN31iDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBRAgent:\n",
        "    def __init__(self, attack_category, training_data, numeric_features, categorical_features, cat_mappings):\n",
        "        self.attack_category = attack_category\n",
        "        self.numeric_features = numeric_features\n",
        "        self.categorical_features = categorical_features\n",
        "        self.cat_mappings = cat_mappings\n",
        "        self.casebase_df = training_data[training_data['attack_cat'] == attack_category].copy()\n",
        "\n",
        "        if self.casebase_df.empty:\n",
        "            self.is_active = False\n",
        "            return\n",
        "        self.is_active = True\n",
        "\n",
        "        # --- Data Preparation for GPU ---\n",
        "        casebase_numeric_np = self.casebase_df[numeric_features].to_numpy(dtype=np.float32)\n",
        "        casebase_categorical_np = self.casebase_df[categorical_features].to_numpy(dtype=np.int32)\n",
        "\n",
        "        self.d_casebase_numeric = cuda.to_device(casebase_numeric_np)\n",
        "        self.d_casebase_categorical = cuda.to_device(casebase_categorical_np)\n",
        "\n",
        "        full_data_mean = training_data[numeric_features].mean()\n",
        "        agent_data_mean = self.casebase_df[numeric_features].mean()\n",
        "\n",
        "        numeric_weights = (agent_data_mean - full_data_mean).abs().values\n",
        "        categorical_weights = np.full(len(categorical_features), 0.1)\n",
        "\n",
        "        total_weight = numeric_weights.sum() + categorical_weights.sum()\n",
        "        if total_weight > 0:\n",
        "            numeric_weights /= total_weight\n",
        "            categorical_weights /= total_weight\n",
        "\n",
        "        self.d_weights_numeric = cuda.to_device(numeric_weights.astype(np.float32))\n",
        "        self.d_weights_categorical = cuda.to_device(categorical_weights.astype(np.float32))\n",
        "\n",
        "        min_vals = self.casebase_df[numeric_features].min().values.astype(np.float32)\n",
        "        max_vals = self.casebase_df[numeric_features].max().values.astype(np.float32)\n",
        "        self.d_min_vals = cuda.to_device(min_vals)\n",
        "        self.d_max_vals = cuda.to_device(max_vals)\n",
        "\n",
        "    def find_most_similar_numba(self, query_case_numeric, query_case_categorical, n=10):\n",
        "        if not self.is_active:\n",
        "            return []\n",
        "\n",
        "        # --- Kernel Launch Setup ---\n",
        "        d_query_numeric = cuda.to_device(query_case_numeric)\n",
        "        d_query_categorical = cuda.to_device(query_case_categorical)\n",
        "\n",
        "        num_cases = self.d_casebase_numeric.shape[0]\n",
        "        d_similarities = cuda.device_array(num_cases, dtype=np.float32)\n",
        "\n",
        "        threads_per_block = 128\n",
        "        blocks_per_grid = (num_cases + (threads_per_block - 1)) // threads_per_block\n",
        "\n",
        "        # --- Launch the Kernel ---\n",
        "        similarity_kernel[blocks_per_grid, threads_per_block](\n",
        "            self.d_casebase_numeric, self.d_casebase_categorical,\n",
        "            d_query_numeric, d_query_categorical,\n",
        "            self.d_weights_numeric, self.d_weights_categorical,\n",
        "            self.d_min_vals, self.d_max_vals,\n",
        "            d_similarities\n",
        "        )\n",
        "\n",
        "        # --- Retrieve and Process Results ---\n",
        "        similarities_host = d_similarities.copy_to_host()\n",
        "        n = min(n, len(similarities_host))\n",
        "        top_n_indices = np.argpartition(similarities_host, -n)[-n:]\n",
        "        top_n_indices = top_n_indices[np.argsort(similarities_host[top_n_indices])][::-1]\n",
        "\n",
        "        top_scores = similarities_host[top_n_indices]\n",
        "        top_cases = self.casebase_df.iloc[top_n_indices]\n",
        "\n",
        "        results = []\n",
        "        for i in range(len(top_n_indices)):\n",
        "            results.append((top_scores[i], top_cases.iloc[i]))\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "azpRSH2Zo2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IDS:\n",
        "    def __init__(self, training_data, numeric_features, categorical_features, cat_mappings):\n",
        "        self.agents = {}\n",
        "        self.categories = training_data['attack_cat'].unique()\n",
        "        self.numeric_features = numeric_features\n",
        "        self.categorical_features = categorical_features\n",
        "\n",
        "        print(\"Initializing agents and transferring data to GPU...\")\n",
        "        for category in self.categories:\n",
        "            self.agents[category] = CBRAgent(category, training_data, numeric_features, categorical_features, cat_mappings)\n",
        "        print(\"All agents initialized.\")\n",
        "\n",
        "    def _get_top_n_votes(self, test_case, n=10):\n",
        "        \"\"\"Helper method to get the list of top N predicted categories.\"\"\"\n",
        "        all_votes = []\n",
        "        query_numeric = test_case[self.numeric_features].to_numpy(dtype=np.float32)\n",
        "        query_categorical = test_case[self.categorical_features].to_numpy(dtype=np.int32)\n",
        "\n",
        "        for agent in self.agents.values():\n",
        "            all_votes.extend(agent.find_most_similar_numba(query_numeric, query_categorical, n))\n",
        "\n",
        "        all_votes.sort(reverse=True, key=lambda x: x[0])\n",
        "        top_n_overall = all_votes[:n]\n",
        "\n",
        "        return [case['attack_cat'] for _, case in top_n_overall]\n",
        "\n",
        "    def classify(self, test_case, n=10):\n",
        "        \"\"\"Performs majority vote to classify a case.\"\"\"\n",
        "        vote_list = self._get_top_n_votes(test_case, n)\n",
        "        if not vote_list:\n",
        "            return \"Unknown\"\n",
        "        return max(set(vote_list), key=vote_list.count)"
      ],
      "metadata": {
        "id": "8YNRIvVjo5bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, numeric_features, categorical_features, cat_mappings=None):\n",
        "    if cat_mappings is None:\n",
        "        cat_mappings = {}\n",
        "        is_training = True\n",
        "    else:\n",
        "        is_training = False\n",
        "\n",
        "    for col in categorical_features:\n",
        "        if is_training:\n",
        "            df[col], mapping = pd.factorize(df[col])\n",
        "            cat_mappings[col] = {label: i for i, label in enumerate(mapping)}\n",
        "        else:\n",
        "            mapping = cat_mappings[col]\n",
        "            df[col] = df[col].map(mapping).fillna(-1).astype(np.int32)\n",
        "\n",
        "    return df, cat_mappings\n",
        "\n",
        "def run_table_2_evaluation(ids, test_df):\n",
        "    \"\"\"\n",
        "    Runs the vote distribution analysis to generate results similar to Table 2.\n",
        "    It takes 1000 samples per attack type and counts how many votes the correct agent gets.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Running Table 2 Evaluation (Agent Vote Distribution) ---\")\n",
        "\n",
        "    # Use the original, non-encoded labels for filtering\n",
        "    original_test_df = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "    original_test_df.columns = original_test_df.columns.str.strip()\n",
        "\n",
        "    results = pd.DataFrame(index=range(11))\n",
        "\n",
        "    for category in ids.categories:\n",
        "        print(f\"  Analyzing category: {category}\")\n",
        "\n",
        "        # Get up to 1000 test cases for the current category\n",
        "        category_cases_indices = original_test_df[original_test_df['attack_cat'] == category].index\n",
        "        sample_size = min(1000, len(category_cases_indices))\n",
        "        if sample_size == 0:\n",
        "            results[category] = 0\n",
        "            continue\n",
        "\n",
        "        sample_indices = np.random.choice(category_cases_indices, sample_size, replace=False)\n",
        "        test_sample = test_df.loc[sample_indices]\n",
        "\n",
        "        vote_counts = defaultdict(int)\n",
        "        for _, test_case in test_sample.iterrows():\n",
        "            top_votes = ids._get_top_n_votes(test_case, n=10)\n",
        "            correct_votes = top_votes.count(category)\n",
        "            vote_counts[correct_votes] += 1\n",
        "\n",
        "        # Add the results for this category to the DataFrame\n",
        "        for i in range(11):\n",
        "            results.loc[i, category] = vote_counts[i]\n",
        "\n",
        "    results.index.name = \"Vote Count\"\n",
        "    return results.fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "ScUowuXdo8jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table 2 below is when 1000 cases are retrieved from each agent. But there are some agents that didn't have fully 1000 cases. Probably the test data isn't contain many that agent's case."
      ],
      "metadata": {
        "id": "rDSprYfm2-RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Loading data with pandas...\")\n",
        "        train_df = pd.read_csv('UNSW_NB15_training-set.csv')\n",
        "        test_df = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
        "        train_df.columns = train_df.columns.str.strip()\n",
        "        test_df.columns = test_df.columns.str.strip()\n",
        "\n",
        "        print(\"Preprocessing data for GPU...\")\n",
        "        numeric_features = train_df.select_dtypes(include=np.number).columns.drop(['id', 'label'], errors='ignore').tolist()\n",
        "        categorical_features = train_df.select_dtypes(include=['object']).columns.drop(['attack_cat'], errors='ignore').tolist()\n",
        "\n",
        "        train_df, cat_mappings = preprocess_data(train_df, numeric_features, categorical_features)\n",
        "        test_df, _ = preprocess_data(test_df, numeric_features, categorical_features, cat_mappings)\n",
        "\n",
        "        ids = IDS(train_df, numeric_features, categorical_features, cat_mappings)\n",
        "\n",
        "        # --- Run Table 2 Analysis ---\n",
        "        table_2_results = run_table_2_evaluation(ids, test_df)\n",
        "        print(\"\\n--- Table 2: Agent Voting Performance (1000 cases per agent) ---\")\n",
        "        print(table_2_results.to_string())\n",
        "\n",
        "        # --- Run Table 3 Analysis (Classification Report) ---\n",
        "        EVALUATION_SAMPLE_SIZE = 50000\n",
        "        print(f\"\\n--- Running Table 3 Evaluation (Classification Report on {EVALUATION_SAMPLE_SIZE} cases) ---\")\n",
        "        test_sample = test_df.sample(EVALUATION_SAMPLE_SIZE)\n",
        "\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        for i, (_, test_case) in enumerate(test_sample.iterrows()):\n",
        "            if (i + 1) % 500 == 0:\n",
        "                print(f\"  Processed {i + 1}/{len(test_sample)} cases...\")\n",
        "\n",
        "            true_labels.append(test_case['attack_cat'])\n",
        "            predicted_labels.append(ids.classify(test_case))\n",
        "\n",
        "        print(\"Evaluation Complete.\")\n",
        "\n",
        "        from sklearn.metrics import classification_report\n",
        "        print(\"\\n--- Classification Report ---\")\n",
        "        print(classification_report(true_labels, predicted_labels, zero_division=0))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nERROR: Make sure 'UNSW_NB15_training-set.csv' and 'UNSW_NB15_testing-set.csv' are present.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "        print(\"Please ensure your Numba and CUDA environments are set up correctly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVdE06YEEKWb",
        "outputId": "d7e2bf22-04ed-4bb7-cda0-7766f3b9ff84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data with pandas...\n",
            "Preprocessing data for GPU...\n",
            "Initializing agents and transferring data to GPU...\n",
            "All agents initialized.\n",
            "\n",
            "--- Running Table 2 Evaluation (Agent Vote Distribution) ---\n",
            "  Analyzing category: Normal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 14 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 16 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 9 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 82 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 96 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Analyzing category: Backdoor\n",
            "  Analyzing category: Analysis\n",
            "  Analyzing category: Fuzzers\n",
            "  Analyzing category: Shellcode\n",
            "  Analyzing category: Reconnaissance\n",
            "  Analyzing category: Exploits\n",
            "  Analyzing category: DoS\n",
            "  Analyzing category: Worms\n",
            "  Analyzing category: Generic\n",
            "\n",
            "--- Table 2: Agent Voting Performance (1000 cases per agent) ---\n",
            "            Normal  Backdoor  Analysis  Fuzzers  Shellcode  Reconnaissance  Exploits  DoS  Worms  Generic\n",
            "Vote Count                                                                                               \n",
            "0               29       210       650      311        301             525       318  903     42      394\n",
            "1               68        10        22      126         51             212        57   75      2        4\n",
            "2               87         6         5      155         16              93       139   18      0       14\n",
            "3              104         1         0      142          4              30       159    2      0       11\n",
            "4               59         0         0      102          5               9       143    1      0        4\n",
            "5               32         0         0       50          0               2       101    1      0        9\n",
            "6               24         2         0       22          0              40        46    0      0       78\n",
            "7               14        92         0       26          1               1        24    0      0       34\n",
            "8               10        33         0       21          0              64        11    0      0       26\n",
            "9               23       123         0       36          0              15         2    0      0       83\n",
            "10             550       106         0        9          0               9         0    0      0      343\n",
            "\n",
            "--- Running Table 3 Evaluation (Classification Report on 50000 cases) ---\n",
            "  Processed 500/50000 cases...\n",
            "  Processed 1000/50000 cases...\n",
            "  Processed 1500/50000 cases...\n",
            "  Processed 2000/50000 cases...\n",
            "  Processed 2500/50000 cases...\n",
            "  Processed 3000/50000 cases...\n",
            "  Processed 3500/50000 cases...\n",
            "  Processed 4000/50000 cases...\n",
            "  Processed 4500/50000 cases...\n",
            "  Processed 5000/50000 cases...\n",
            "  Processed 5500/50000 cases...\n",
            "  Processed 6000/50000 cases...\n",
            "  Processed 6500/50000 cases...\n",
            "  Processed 7000/50000 cases...\n",
            "  Processed 7500/50000 cases...\n",
            "  Processed 8000/50000 cases...\n",
            "  Processed 8500/50000 cases...\n",
            "  Processed 9000/50000 cases...\n",
            "  Processed 9500/50000 cases...\n",
            "  Processed 10000/50000 cases...\n",
            "  Processed 10500/50000 cases...\n",
            "  Processed 11000/50000 cases...\n",
            "  Processed 11500/50000 cases...\n",
            "  Processed 12000/50000 cases...\n",
            "  Processed 12500/50000 cases...\n",
            "  Processed 13000/50000 cases...\n",
            "  Processed 13500/50000 cases...\n",
            "  Processed 14000/50000 cases...\n",
            "  Processed 14500/50000 cases...\n",
            "  Processed 15000/50000 cases...\n",
            "  Processed 15500/50000 cases...\n",
            "  Processed 16000/50000 cases...\n",
            "  Processed 16500/50000 cases...\n",
            "  Processed 17000/50000 cases...\n",
            "  Processed 17500/50000 cases...\n",
            "  Processed 18000/50000 cases...\n",
            "  Processed 18500/50000 cases...\n",
            "  Processed 19000/50000 cases...\n",
            "  Processed 19500/50000 cases...\n",
            "  Processed 20000/50000 cases...\n",
            "  Processed 20500/50000 cases...\n",
            "  Processed 21000/50000 cases...\n",
            "  Processed 21500/50000 cases...\n",
            "  Processed 22000/50000 cases...\n",
            "  Processed 22500/50000 cases...\n",
            "  Processed 23000/50000 cases...\n",
            "  Processed 23500/50000 cases...\n",
            "  Processed 24000/50000 cases...\n",
            "  Processed 24500/50000 cases...\n",
            "  Processed 25000/50000 cases...\n",
            "  Processed 25500/50000 cases...\n",
            "  Processed 26000/50000 cases...\n",
            "  Processed 26500/50000 cases...\n",
            "  Processed 27000/50000 cases...\n",
            "  Processed 27500/50000 cases...\n",
            "  Processed 28000/50000 cases...\n",
            "  Processed 28500/50000 cases...\n",
            "  Processed 29000/50000 cases...\n",
            "  Processed 29500/50000 cases...\n",
            "  Processed 30000/50000 cases...\n",
            "  Processed 30500/50000 cases...\n",
            "  Processed 31000/50000 cases...\n",
            "  Processed 31500/50000 cases...\n",
            "  Processed 32000/50000 cases...\n",
            "  Processed 32500/50000 cases...\n",
            "  Processed 33000/50000 cases...\n",
            "  Processed 33500/50000 cases...\n",
            "  Processed 34000/50000 cases...\n",
            "  Processed 34500/50000 cases...\n",
            "  Processed 35000/50000 cases...\n",
            "  Processed 35500/50000 cases...\n",
            "  Processed 36000/50000 cases...\n",
            "  Processed 36500/50000 cases...\n",
            "  Processed 37000/50000 cases...\n",
            "  Processed 37500/50000 cases...\n",
            "  Processed 38000/50000 cases...\n",
            "  Processed 38500/50000 cases...\n",
            "  Processed 39000/50000 cases...\n",
            "  Processed 39500/50000 cases...\n",
            "  Processed 40000/50000 cases...\n",
            "  Processed 40500/50000 cases...\n",
            "  Processed 41000/50000 cases...\n",
            "  Processed 41500/50000 cases...\n",
            "  Processed 42000/50000 cases...\n",
            "  Processed 42500/50000 cases...\n",
            "  Processed 43000/50000 cases...\n",
            "  Processed 43500/50000 cases...\n",
            "  Processed 44000/50000 cases...\n",
            "  Processed 44500/50000 cases...\n",
            "  Processed 45000/50000 cases...\n",
            "  Processed 45500/50000 cases...\n",
            "  Processed 46000/50000 cases...\n",
            "  Processed 46500/50000 cases...\n",
            "  Processed 47000/50000 cases...\n",
            "  Processed 47500/50000 cases...\n",
            "  Processed 48000/50000 cases...\n",
            "  Processed 48500/50000 cases...\n",
            "  Processed 49000/50000 cases...\n",
            "  Processed 49500/50000 cases...\n",
            "  Processed 50000/50000 cases...\n",
            "Evaluation Complete.\n",
            "\n",
            "--- Classification Report ---\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       405\n",
            "      Backdoor       0.05      0.60      0.10       361\n",
            "           DoS       0.06      0.00      0.01      2488\n",
            "      Exploits       0.26      0.31      0.28      6763\n",
            "       Fuzzers       0.12      0.21      0.15      3731\n",
            "       Generic       1.00      0.56      0.71     11421\n",
            "        Normal       0.71      0.73      0.72     22455\n",
            "Reconnaissance       0.31      0.16      0.21      2133\n",
            "     Shellcode       0.00      0.00      0.00       218\n",
            "         Worms       0.00      0.00      0.00        25\n",
            "\n",
            "      accuracy                           0.52     50000\n",
            "     macro avg       0.25      0.26      0.22     50000\n",
            "  weighted avg       0.61      0.52      0.55     50000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}